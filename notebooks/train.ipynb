{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8684c458",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1 切换目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c80474a-d620-47ec-a76f-bb74395be086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/featurize/vits-zh\n",
      "attentions.py  \u001b[0m\u001b[01;34mlogs\u001b[0m/              \u001b[01;34mmonotonic_align\u001b[0m/  \u001b[01;34mtext\u001b[0m/          \u001b[01;34mwave_data\u001b[0m/\n",
      "commons.py     losses.py          preprocess.py     train.py\n",
      "\u001b[01;34mconfigs\u001b[0m/       mel_processing.py  \u001b[01;34m__pycache__\u001b[0m/      transforms.py\n",
      "data_utils.py  models.py          requirements.txt  usage.txt\n",
      "\u001b[01;34mfilelists\u001b[0m/     modules.py         test.py           utils.py\n"
     ]
    }
   ],
   "source": [
    "%cd /home/workspace/vits_for_chinese  # 具体目录看实际情况调整\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb8522",
   "metadata": {},
   "source": [
    "#### 2 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033e710-e6fe-47ed-bf9b-259501adbbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from train import Trainer\n",
    "\n",
    "hps = utils.get_hparams_from_file('configs/config.json')\n",
    "trainer = Trainer(hps)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1adbcb-6374-4125-a332-0515ed005050",
   "metadata": {},
   "source": [
    "#### 3.模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8430ad-28fd-4e7d-a18c-57b01462aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "import text\n",
    "from models import VITS_Model\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "hps = utils.get_hparams_from_file('configs/config.json')\n",
    "model = VITS_Model(**hps.model)\n",
    "model.load_state_dict(torch.load('logs/model/epoch_latest/generator.ckpt', map_location=\"cpu\"))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d69e9-dbdb-40df-8732-eb6bfc15b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_emb = torch.load('dataset/embed/wav_DLC_Story_CN/AUDIO_DLC_Story_CN 00003.emb.pt').unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8f99e-c9fa-4c96-b08b-2a8c73a990a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_text = \"这些尝试大部分集中于通用LlM上\"\n",
    "phonemes = text.pypinyin_g2p(in_text)\n",
    "input_ids = torch.LongTensor(text.tokens2ids(phonemes)).unsqueeze(0)\n",
    "lengths = torch.LongTensor([input_ids.size(1)])\n",
    "t_audio = model.infer(input_ids, lengths, speaker_emb)\n",
    "audio = t_audio[0][0,0].data.cpu().float().numpy()\n",
    "display(Audio(audio, rate=hps.data.sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e92946-53ac-4922-867f-b016c05da98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (in_text, sid, noise_scale=0.3, noise_scale_w=0.3, length_scale=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dac4fc32d5c7eb33424b3c48f2745f9e3f9ffefaa1ba14993f8af344c5fea579"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
